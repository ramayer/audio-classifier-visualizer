{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import in case module was modified\n",
    "import importlib\n",
    "import audio_classifier_visualizer as acv\n",
    "importlib.reload(acv)\n",
    "raven_file_helper = acv.RavenFileHelper()\n",
    "audio_file_processor = acv.AudioFileProcessor()\n",
    "audio_file_visualizer = acv.AudioFileVisualizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from audio_classifier_visualizer import RavenLabel\n",
    "\n",
    "audio_file = 'CEB1_20111010_000000.wav'\n",
    "start_time = 0\n",
    "duration = 60 * 60\n",
    "AVES_SR = 4000\n",
    "audio_path = '/tmp/test.wav'\n",
    "\n",
    "sr = AVES_SR\n",
    "# y = raven_file_helper.get_downsampled_tensor(audio_file,start_time,duration+start_time,new_sr=AVES_SR)\n",
    "\n",
    "# Create some demo labels\n",
    "demo_labels = [\n",
    "    RavenLabel(\n",
    "        bt=20.0,  # begin time\n",
    "        et=30.0,  # end time \n",
    "        lf=200,   # low frequency\n",
    "        hf=600,   # high frequency\n",
    "        duration=10.0,\n",
    "        audio_file=audio_path,\n",
    "        t1=\"demo1\",\n",
    "        t2=None,\n",
    "        t3=None,\n",
    "        notes=\"Demo annotation 1\",\n",
    "        score=0.95,\n",
    "        ravenfile=None\n",
    "    ),\n",
    "    RavenLabel(\n",
    "        bt=100.0,\n",
    "        et=120.0,\n",
    "        lf=300,\n",
    "        hf=900, \n",
    "        duration=20.0,\n",
    "        audio_file=audio_path,\n",
    "        t1=\"demo2\",\n",
    "        t2=None,\n",
    "        t3=None,\n",
    "        notes=\"Demo annotation 2\", \n",
    "        score=0.85,\n",
    "        ravenfile=None\n",
    "    )\n",
    "]\n",
    "\n",
    "y = raven_file_helper.load_entire_wav_file(audio_path, new_sr = AVES_SR)\n",
    "print(y.shape)\n",
    "print(sr)\n",
    "y = y.flatten().to(torch.float16)[0:10000]\n",
    "audio_file_visualizer.visualize_audio_file_fragment(\n",
    "    f\"{audio_file} and scores\",\n",
    "    '/tmp/1.png',\n",
    "    audio_path,\n",
    "    torch.rand(y.shape[0]) * 0.1 + 0.45,\n",
    "    torch.rand(y.shape[0]) * 0.1 + 0.45,\n",
    "    audio_file_processor,\n",
    "    start_time=0,\n",
    "    end_time=60*5,\n",
    "    colormap='raw',\n",
    "    width=16,\n",
    "    height=3.5,\n",
    "    labels=demo_labels  # Add the demo labels\n",
    ")\n",
    "from PIL import Image\n",
    "import IPython.display as ipd\n",
    "ipd.display(Image.open('/tmp/1.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some test labels\n",
    "test_labels = [\n",
    "    acv.RavenLabel(\n",
    "        bt=10.0,  # begin time \n",
    "        et=15.0,  # end time\n",
    "        lf=100,   # low frequency\n",
    "        hf=500,   # high frequency\n",
    "        duration=5.0,\n",
    "        audio_file=audio_path,\n",
    "        t1=\"test1\",\n",
    "        t2=None,\n",
    "        t3=None, \n",
    "        notes=\"Test annotation 1\",\n",
    "        score=0.9,\n",
    "        ravenfile=None\n",
    "    ),\n",
    "    acv.RavenLabel(\n",
    "        bt=30.0,\n",
    "        et=40.0, \n",
    "        lf=200,\n",
    "        hf=800,\n",
    "        duration=10.0,\n",
    "        audio_file=audio_path,\n",
    "        t1=\"test2\", \n",
    "        t2=None,\n",
    "        t3=None,\n",
    "        notes=\"Test annotation 2\",\n",
    "        score=0.8,\n",
    "        ravenfile=None\n",
    "    )\n",
    "]\n",
    "\n",
    "# Visualize with the test labels\n",
    "audio_file_visualizer.visualize_audio_file_fragment(\n",
    "    f\"{audio_file} with annotations\",\n",
    "    '/tmp/2.png',\n",
    "    audio_path,\n",
    "    torch.rand(y.shape[0]) * 0.1 + 0.45,\n",
    "    torch.rand(y.shape[0]) * 0.1 + 0.45,\n",
    "    audio_file_processor,\n",
    "    start_time=0,\n",
    "    end_time=60*5,\n",
    "    colormap='raw',\n",
    "    width=16,\n",
    "    height=3.5,\n",
    "    labels=test_labels\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "from PIL import Image\n",
    "import IPython.display as ipd\n",
    "ipd.display(Image.open('/tmp/2.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-classifier-visualizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
