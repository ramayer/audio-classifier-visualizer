{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet git+https://github.com/ramayer/elephant-rumble-inference@v0.9.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import elephant_rumble_inference as eri\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE = 'cpu'\n",
    "aves_hubert_model          = eri.AvesTorchaudioWrapper().to(DEVICE)\n",
    "elephant_rumble_classifier = eri.ElephantRumbleClassifier().to('cpu')\n",
    "audio_file_processor       = eri.AudioFileProcessor(aves_hubert_model,elephant_rumble_classifier,device=DEVICE)\n",
    "elephant_rumble_classifier.load_pretrained_weights('best.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/tmp/test.wav'\n",
    "scores = audio_file_processor.classify_wave_file_for_rumbles(audio_path, limit_audio_hours=1)\n",
    "feature_rate = audio_file_processor.rumble_sr // audio_file_processor.audio_samples_per_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import in case module was modified\n",
    "import importlib\n",
    "import audio_classifier_visualizer as acv\n",
    "importlib.reload(acv)\n",
    "raven_file_helper = acv.RavenFileHelper()\n",
    "audio_file_processor = acv.AudioFileProcessor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from audio_classifier_visualizer import RavenLabel\n",
    "\n",
    "audio_file = 'CEB1_20111010_000000.wav'\n",
    "start_time = 0\n",
    "duration = 60 * 60\n",
    "AVES_SR = 4000\n",
    "audio_path = '/tmp/test.wav'\n",
    "\n",
    "sr = AVES_SR\n",
    "# y = raven_file_helper.get_downsampled_tensor(audio_file,start_time,duration+start_time,new_sr=AVES_SR)\n",
    "\n",
    "# Create some demo labels\n",
    "demo_labels = [\n",
    "    RavenLabel(\n",
    "        bt=20.0,  # begin time\n",
    "        et=30.0,  # end time \n",
    "        lf=200,   # low frequency\n",
    "        hf=600,   # high frequency\n",
    "        duration=10.0,\n",
    "        audio_file=audio_path,\n",
    "        t1=\"demo1\",\n",
    "        t2=None,\n",
    "        t3=None,\n",
    "        notes=\"Demo annotation 1\",\n",
    "        score=0.95,\n",
    "        ravenfile=None\n",
    "    ),\n",
    "    RavenLabel(\n",
    "        bt=100.0,\n",
    "        et=120.0,\n",
    "        lf=300,\n",
    "        hf=900, \n",
    "        duration=20.0,\n",
    "        audio_file=audio_path,\n",
    "        t1=\"demo2\",\n",
    "        t2=None,\n",
    "        t3=None,\n",
    "        notes=\"Demo annotation 2\", \n",
    "        score=0.85,\n",
    "        ravenfile=None\n",
    "    )\n",
    "]\n",
    "audio_file_visualizer = acv.AudioFileVisualizer(audio_path, start_time=0, end_time=60*5)\n",
    "\n",
    "\n",
    "#y = raven_file_helper.load_entire_wav_file(audio_path, new_sr = AVES_SR)\n",
    "#print(y.shape)\n",
    "#print(sr)\n",
    "#y = y.flatten().to(torch.float16)[0:10000]\n",
    "audio_file_visualizer.visualize_audio_file_fragment(\n",
    "    f\"{audio_file} and scores\",\n",
    "    '/tmp/1.png',\n",
    "    # audio_path,\n",
    "    scores[0:468,1],\n",
    "    scores[0:468,0],\n",
    "    audio_file_processor,\n",
    "    start_time=0,\n",
    "    end_time=60*5,\n",
    "    colormap='raw',\n",
    "    width=16,\n",
    "    height=3.5,\n",
    "    labels=demo_labels  # Add the demo labels\n",
    ")\n",
    "from PIL import Image\n",
    "import IPython.display as ipd\n",
    "ipd.display(Image.open('/tmp/1.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-classifier-visualizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
